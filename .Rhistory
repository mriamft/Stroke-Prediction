ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#make predictions using the ctree information gain tree on the test data
testPred <- predict(stroke_ctree, newdata = testData)
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 70% of data for training, 30% of data for testing
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#splitting 70% of data for training, 30% of data for testing
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#splitting 70% of data for training, 30% of data for testing
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#splitting 70% of data for training, 30% of data for testing
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#make predictions using the ctree information gain tree on the test data
testPred <- predict(stroke_ctree, newdata = testData)
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 80% of data for training, 20% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.80 , 0.20))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#make predictions using the ctree information gain tree on the test data
testPred <- predict(stroke_ctree, newdata = testData)
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 85% of data for training, 15% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.85 , 0.15))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#make predictions using the ctree information gain tree on the test data
testPred <- predict(stroke_ctree, newdata = testData)
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 70% of data for training, 30% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the rpart gini index tree
library('rpart')
library('rpart.plot')
tree <- rpart(myFormula, data = trainData,method = 'class')
rpart.plot(tree)
#make predictions using the rpart gini index tree on the test data
testPred <- predict(tree, newdata = testData,type = 'class')
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 80% of data for training, 20% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.80 , 0.20))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the rpart gini index tree
library('rpart')
library('rpart.plot')
tree <- rpart(myFormula, data = trainData,method = 'class')
rpart.plot(tree)
#make predictions using the rpart gini index tree on the test data
testPred <- predict(tree, newdata = testData,type = 'class')
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 85% of data for training, 15% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.85 , 0.15))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the rpart gini index tree
library('rpart')
library('rpart.plot')
tree <- rpart(myFormula, data = trainData,method = 'class')
rpart.plot(tree)
#make predictions using the rpart gini index tree on the test data
testPred <- predict(tree, newdata = testData,type = 'class')
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
set.seed(123)
library('MASS')
library("discretization")
cutPoints(data$age,data$stroke)
data<-read.csv("Dataset/healthcare-dataset-stroke-data.csv")
data<-read.csv("Dataset/healthcare-dataset-stroke-data.csv")
# import necessary libraries
library(tidyverse)
library(ggplot2)
library(lubridate)
library(magrittr)
library(dplyr)
library(tidyr)
library(readr)
library(outliers)
library(caret)
library(DMwR2)
library(tidyverse)
library(lubridate)
library(skimr)
library(janitor)
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(gridExtra)
data$bmi[data$bmi=="N/A"] <-NA
sum(is.na(data))
# Converting bmi to numeric
data$bmi <- as.numeric(as.character(data$bmi))
# Checking bmi type
class(data$bmi)
# Replacing null values with the mean
data$bmi[is.na(data$bmi)]<-mean(data$bmi, na.rm = TRUE)
#Remove outliers:
#install outliers package
library(outliers)
#detect Age outliers
OutAge <- outlier(data$age)
print(OutAge)
#checking the outlier location before delete
indices <- which(data$age == OutAge)
# Print the resulting row indices
print(indices)
#Remove age outlier
data <- data[data$age != OutAge, ]
#detect Average glucose level outliers
OutAvg <- outlier(data$avg_glucose_level)
print(OutAvg)
#Remove Average glucose level outlier
data <- data[data$avg_glucose_level != OutAvg, ]
#detect bmi outliers
OutBMI <- outlier(data$bmi)
print(OutBMI)
#Remove bmi outlier
data <- data[data$bmi != OutBMI, ]
#only one column with Gender "Other"
data[data$gender=="Other", ]
# delete it
data = data[data$gender!="Other", ]
#normalize data
normalize <- function(x){ return ((x - min(x))/ (max(x)- min(x)))}
data$avg_glucose_level= normalize(data$avg_glucose_level)
data$age= normalize(data$age)
data$bmi= normalize(data$bmi)
head(data)
#delete id coloumn
data <-data[,!names(data) %in% c("id", "gender", "Residence_type")]
head(data)
# up the data
library('caret')
library('dplyr')
data$stroke <- as.factor(data$stroke)
data<-upSample(data[,-9],data$stroke, yname="stroke")
plot(data$stroke)
data$stroke<- as.factor(data$stroke)
data <- data %>%group_by(stroke) %>% sample_n(size=500)
myFormula <- stroke ~ age + hypertension +ever_married+avg_glucose_level
#splitting 70% of data for training, 30% of data for testing
library('C50')
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the c5.0 gain ratio tree
strokeTree <- C5.0(myFormula, data=trainData)
summary(strokeTree)
plot(strokeTree)
#make predictions using the c5.0 gain ratio tree on the test data
testPred <- predict(strokeTree, newdata = testData)
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
#splitting 80% of data for training, 20% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.80 , 0.20))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the c5.0 gain ratio tree
strokeTree <- C5.0(myFormula, data=trainData)
summary(strokeTree)
plot(strokeTree)
#make predictions using the c5.0 gain ratio tree on the test data
testPred <- predict(strokeTree, newdata = testData)
#create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 85% of data for training, 15% of data for testing
trctrl <- trainControl(method = "cv", number = 10, savePredictions=TRUE)
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.85 , 0.15))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the c5.0 gain ratio tree
strokeTree <- C5.0(myFormula, data=trainData,)
summary(strokeTree)
plot(strokeTree)
#make predictions using the c5.0 gain ratio tree on the test data
testPred <- predict(strokeTree, newdata = testData)
#create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
set.seed(123)
library('MASS')
library("discretization")
cutPoints(data$age,data$stroke)
data$age= cut(data$age, breaks= seq(0,1, by=0.3),right=TRUE)
cutPoints(data$avg_glucose_level,data$stroke)
data$avg_glucose_level	= cut(data$avg_glucose_level, breaks= seq(0,1, by=0.6),right=TRUE)
cutPoints(data$bmi,data$stroke)
data$bmi	= cut(data$bmi, breaks= seq(0,0.7, by=0.35),right=TRUE)
data$hypertension <- as.factor(data$hypertension )
data$heart_disease <- as.factor(data$heart_disease )
data$ever_married   <- as.factor(data$ever_married  )
data$work_type   <- as.factor(data$work_type  )
data$smoking_status <- as.factor(data$smoking_status )
#splitting 70% of data for training, 30% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#make predictions using the ctree information gain tree on the test data
testPred <- predict(stroke_ctree, newdata = testData)
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 80% of data for training, 20% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.80 , 0.20))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#make predictions using the ctree information gain tree on the test data
testPred <- predict(stroke_ctree, newdata = testData)
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 85% of data for training, 15% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.85 , 0.15))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the ctree information gain tree
library(party)
library(plyr)
library(readr)
stroke_ctree <- ctree(myFormula, data=trainData)
print(stroke_ctree)
plot(stroke_ctree,type="simple")
plot(stroke_ctree)
#make predictions using the ctree information gain tree on the test data
testPred <- predict(stroke_ctree, newdata = testData)
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 70% of data for training, 30% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.70 , 0.30))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the rpart gini index tree
library('rpart')
library('rpart.plot')
tree <- rpart(myFormula, data = trainData,method = 'class')
rpart.plot(tree)
#make predictions using the rpart gini index tree on the test data
testPred <- predict(tree, newdata = testData,type = 'class')
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 80% of data for training, 20% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.80 , 0.20))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the rpart gini index tree
library('rpart')
library('rpart.plot')
tree <- rpart(myFormula, data = trainData,method = 'class')
rpart.plot(tree)
#make predictions using the rpart gini index tree on the test data
testPred <- predict(tree, newdata = testData,type = 'class')
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
#splitting 85% of data for training, 15% of data for testing
set.seed(1234)
ind=sample (2, nrow(data), replace=TRUE, prob=c(0.85 , 0.15))
trainData=data[ind==1,]
testData=data[ind==2,]
#train using the trainData and create the rpart gini index tree
library('rpart')
library('rpart.plot')
tree <- rpart(myFormula, data = trainData,method = 'class')
rpart.plot(tree)
#make predictions using the rpart gini index tree on the test data
testPred <- predict(tree, newdata = testData,type = 'class')
##create confusion matrix to evaluate the model's performance
library(caret)
results <- confusionMatrix(testPred, testData$stroke, positive= "1")
acc <- results$overall["Accuracy"]*100
acc
results
as.table(results)
as.matrix(results)
as.matrix(results, what = "overall")
as.matrix(results, what = "classes")
print(results)
